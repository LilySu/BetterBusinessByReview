{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment6Categories.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LilySu/BetterBusinessByReview/blob/master/Sentiment6Categories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gd0wB54uSLRn",
        "colab": {}
      },
      "source": [
        "# !pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gQ9Xna3MJZt",
        "colab_type": "code",
        "outputId": "949d7252-f1fa-4cc6-e03a-8ca5beef9dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "\n",
        "import re\n",
        "import nltk\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import wordnet \n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
        "\n",
        "# from tallylib.sql import getLatestReviews # for django app\n",
        "\n",
        "nltk.download('wordnet')\n",
        "pd.options.display.max_rows = 999\n",
        "pd.options.display.max_columns = 999\n",
        "pd.set_option('display.max_colwidth', 1000)\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrb4n-RwMXxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path = \"/content/drive/My Drive/config/awscli.ini\"\n",
        "# with open(path, 'w') as f:\n",
        "#     f.write(text)\n",
        "\n",
        "# # check AWS CLI key file\n",
        "# !cat /content/drive/My\\ Drive/config/awscli.ini\n",
        "\n",
        "# !export AWS_SHARED_CREDENTIALS_FILE=/content/drive/My\\ Drive/config_/awscli.ini\n",
        "# import os\n",
        "# path = \"/content/drive/My Drive/config/awscli.ini\"\n",
        "# os.environ['AWS_SHARED_CREDENTIALS_FILE'] = path\n",
        "# print(os.environ['AWS_SHARED_CREDENTIALS_FILE'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmCQYD_FMvei",
        "colab_type": "code",
        "outputId": "e936e6ed-a320-4d57-d4ae-a5763e2a9e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/cafesFromDB.csv')\n",
        "#command ran in database\n",
        "# select * from tallyds.yelp_review where text like '%cafe%' order by business_id limit 500;\n",
        "\n",
        "df = df[df['business_id'] == '0d6kx6Jlocw77y1J9nbqMA']# just work with one popular cafe\n",
        "\n",
        "def tokenizer(doc):\n",
        "     return [token for token in simple_preprocess(doc) \n",
        "             if token not in STOPWORDS]\n",
        "\n",
        "\n",
        "def related_to_food(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('food.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_service(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('service.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_speed(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('speed.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_price(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('price.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_ambience(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('ambience.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_experience(doc):\n",
        "  word_similarity_list = []\n",
        "  for review_word in doc:\n",
        "    syns = wordnet.synsets(review_word) \n",
        "    if len(syns) > 0:\n",
        "      w1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "      w2 = wordnet.synset('experience.n.01') \n",
        "      word_similarity_score = w1.wup_similarity(w2)\n",
        "      if word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "        word_similarity_list.append(review_word)\n",
        "  return word_similarity_list\n",
        "\n",
        "def extract_subject_related_words():\n",
        "  df['text'] = df['text'].apply(lambda x:\" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
        "  df['cleaned'] = df['text'].apply(tokenizer)\n",
        "  df['words_related_to_food'] = df['cleaned'].apply(related_to_food)\n",
        "  df['words_related_to_service'] = df['cleaned'].apply(related_to_service)\n",
        "  df['words_related_to_speed'] = df['cleaned'].apply(related_to_speed)\n",
        "  df['words_related_to_price'] = df['cleaned'].apply(related_to_price)\n",
        "  df['words_related_to_ambience'] = df['cleaned'].apply(related_to_ambience)\n",
        "  df['words_related_to_experience'] = df['cleaned'].apply(related_to_experience)\n",
        "\n",
        "extract_subject_related_words()\n",
        "df.sample(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>datetime</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>text</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>words_related_to_food</th>\n",
              "      <th>words_related_to_service</th>\n",
              "      <th>words_related_to_speed</th>\n",
              "      <th>words_related_to_price</th>\n",
              "      <th>words_related_to_ambience</th>\n",
              "      <th>words_related_to_experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>1O7pQxL5DMOr7J35y6GjQQ</td>\n",
              "      <td>0d6kx6Jlocw77y1J9nbqMA</td>\n",
              "      <td>e5q7ScqfQ8A4_2j2P-uCLQ</td>\n",
              "      <td>5</td>\n",
              "      <td>2009-11-21 19:27:56</td>\n",
              "      <td>2009-11-21</td>\n",
              "      <td>19:27:56</td>\n",
              "      <td>Scratch Pastries is truly a blessing to South Scottsdale as soon as you step in it feels like you have temporarily escaped your every day surroundings and are about to dine at an authentic French Cafe Although the interior design is quite charming which includes the perfect pink walls that are decorated with unique photographs that the chef took himself as I learned he is also a very accomplished photographer eyes should immediately turn to the beautiful waitress who is always the greatest pleasure and extremely attentive Everything from their sumptuous vanilla green tea to the delicious sandwiches and crepes are amazing Everything that I have tried at Scratch has been quite the treat although I would definitely recommend the BLTC accompanied with one of their many delicate fresh made soups As I have been a Scratch patron for some time I decided to try the restaurant for dinner as they recently opened Wednesday Sunday nights I must say I was more than impressed The rich and savory ...</td>\n",
              "      <td>2019-12-29 01:12:25.950277+00</td>\n",
              "      <td>[scratch, pastries, truly, blessing, south, scottsdale, soon, step, feels, like, temporarily, escaped, day, surroundings, dine, authentic, french, cafe, interior, design, charming, includes, perfect, pink, walls, decorated, unique, photographs, chef, took, learned, accomplished, photographer, eyes, immediately, turn, beautiful, waitress, greatest, pleasure, extremely, attentive, sumptuous, vanilla, green, tea, delicious, sandwiches, crepes, amazing, tried, scratch, treat, definitely, recommend, bltc, accompanied, delicate, fresh, soups, scratch, patron, time, decided, try, restaurant, dinner, recently, opened, wednesday, sunday, nights, impressed, rich, savory, flavors, coq, au, vin, chicken, normandy, excellent, house, red, wine, wonderful, french, blend, accompanies, meals, perfectly, adore, dishes, consist, delicious, carrot, puree, smashed, potatoes, goes, ...]</td>\n",
              "      <td>[pastries, tea, sandwiches, treat, soups, dinner, wine, meals, puree, potatoes, sauces, meat, pastries]</td>\n",
              "      <td>[blessing, step, design, time, try, orders, time, try, order, looking]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[scratch, surroundings, pleasure, scratch, scratch, flavors, way, scratch, regret]</td>\n",
              "      <td>[like, eyes, expectations]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  review_id             business_id                 user_id  \\\n",
              "175  1O7pQxL5DMOr7J35y6GjQQ  0d6kx6Jlocw77y1J9nbqMA  e5q7ScqfQ8A4_2j2P-uCLQ   \n",
              "\n",
              "     stars             datetime        date      time  \\\n",
              "175      5  2009-11-21 19:27:56  2009-11-21  19:27:56   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
              "175  Scratch Pastries is truly a blessing to South Scottsdale as soon as you step in it feels like you have temporarily escaped your every day surroundings and are about to dine at an authentic French Cafe Although the interior design is quite charming which includes the perfect pink walls that are decorated with unique photographs that the chef took himself as I learned he is also a very accomplished photographer eyes should immediately turn to the beautiful waitress who is always the greatest pleasure and extremely attentive Everything from their sumptuous vanilla green tea to the delicious sandwiches and crepes are amazing Everything that I have tried at Scratch has been quite the treat although I would definitely recommend the BLTC accompanied with one of their many delicate fresh made soups As I have been a Scratch patron for some time I decided to try the restaurant for dinner as they recently opened Wednesday Sunday nights I must say I was more than impressed The rich and savory ...   \n",
              "\n",
              "                         timestamp  \\\n",
              "175  2019-12-29 01:12:25.950277+00   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           cleaned  \\\n",
              "175  [scratch, pastries, truly, blessing, south, scottsdale, soon, step, feels, like, temporarily, escaped, day, surroundings, dine, authentic, french, cafe, interior, design, charming, includes, perfect, pink, walls, decorated, unique, photographs, chef, took, learned, accomplished, photographer, eyes, immediately, turn, beautiful, waitress, greatest, pleasure, extremely, attentive, sumptuous, vanilla, green, tea, delicious, sandwiches, crepes, amazing, tried, scratch, treat, definitely, recommend, bltc, accompanied, delicate, fresh, soups, scratch, patron, time, decided, try, restaurant, dinner, recently, opened, wednesday, sunday, nights, impressed, rich, savory, flavors, coq, au, vin, chicken, normandy, excellent, house, red, wine, wonderful, french, blend, accompanies, meals, perfectly, adore, dishes, consist, delicious, carrot, puree, smashed, potatoes, goes, ...]   \n",
              "\n",
              "                                                                                       words_related_to_food  \\\n",
              "175  [pastries, tea, sandwiches, treat, soups, dinner, wine, meals, puree, potatoes, sauces, meat, pastries]   \n",
              "\n",
              "                                                   words_related_to_service  \\\n",
              "175  [blessing, step, design, time, try, orders, time, try, order, looking]   \n",
              "\n",
              "    words_related_to_speed words_related_to_price  \\\n",
              "175                     []                     []   \n",
              "\n",
              "                                                              words_related_to_ambience  \\\n",
              "175  [scratch, surroundings, pleasure, scratch, scratch, flavors, way, scratch, regret]   \n",
              "\n",
              "    words_related_to_experience  \n",
              "175  [like, eyes, expectations]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfcc3EqvXaVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = df[(df['words_related_to_food'].map(len) > 1) | (df['words_related_to_service'].map(len) > 1) | (df['words_related_to_speed'].map(len) > 1) | (df['words_related_to_price'].map(len) > 1) | (df['words_related_to_ambience'].map(len) > 1) | (df['words_related_to_experience'].map(len) > 1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piUrNw0LY0os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_list_reviews_containing_subject():\n",
        "  food_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
        "  service_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
        "  speed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
        "  price_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
        "  ambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
        "  experience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()\n",
        "  return food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list\n",
        "\n",
        "food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list = get_list_reviews_containing_subject()\n",
        "  # food_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
        "  # service_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
        "  # speed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
        "  # price_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
        "  # ambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
        "  # experience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyRnbR1xTHif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_score(sentence):\n",
        "    # Create a SentimentIntensityAnalyzer object. \n",
        "    sid_obj = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # polarity_scores method of SentimentIntensityAnalyzer oject gives a sentiment dictionary. which contains pos, neg, neu, and compound scores. \n",
        "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "\n",
        "    return sentiment_dict\n",
        "\n",
        "def get_sentiment(review_list):\n",
        "    all_sentiments = []\n",
        "    compounds = []\n",
        "\n",
        "    if len(review_list) > 0:\n",
        "        for review in review_list:\n",
        "            score = sentiment_score(review)\n",
        "            all_sentiments.append(score)\n",
        "\n",
        "    if len(all_sentiments) > 0:\n",
        "        for sentiment_dict in all_sentiments:\n",
        "            compound = sentiment_dict['compound']\n",
        "            compounds.append(compound)\n",
        "\n",
        "    if len(compounds) > 0:\n",
        "        avg_sentiment = sum(compounds) / len(compounds)\n",
        "    \n",
        "    else:\n",
        "        avg_sentiment = None\n",
        "\n",
        "    return avg_sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hraJj50iTYHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_scores():\n",
        "  if len(food_review_list) > 0:\n",
        "    food_sentiment_score = round((get_sentiment(food_review_list))*150)\n",
        "  else: \n",
        "    food_sentiment_score = 75\n",
        "  if len(service_review_list) > 0:\n",
        "    service_sentiment_score = round((get_sentiment(service_review_list))*150)\n",
        "  else: \n",
        "    service_sentiment_score = 75\n",
        "  if len(speed_review_list) > 0:\n",
        "    speed_sentiment_score = round((get_sentiment(speed_review_list))*150)\n",
        "  else: \n",
        "    speed_sentiment_score = 75\n",
        "  if len(price_review_list) > 0:\n",
        "    price_sentiment_score = round((get_sentiment(price_review_list))*150)\n",
        "  else: \n",
        "    price_sentiment_score = 75\n",
        "  if len(ambience_review_list) > 0:\n",
        "    ambience_sentiment_score = round((get_sentiment(ambience_review_list))*150)\n",
        "  else: \n",
        "    ambience_sentiment_score = 75\n",
        "  if len(experience_review_list) > 0:\n",
        "    experience_sentiment_score = round((get_sentiment(experience_review_list))*150)\n",
        "  else: \n",
        "    experience_sentiment_score = 75\n",
        "  return food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score\n",
        "\n",
        "\n",
        "food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score = get_scores()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvetyqFLUgH5",
        "colab_type": "code",
        "outputId": "f5440a24-c0a6-48db-b581-f7e7045356ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "results = json.dumps([\n",
        "        { 'subject': 'Food', 'data1': food_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "        { 'subject': 'Service', 'data1': service_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "        { 'subject': 'Speed', 'data1': speed_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "        { 'subject': 'Price', 'data1': price_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "        { 'subject': 'Ambience', 'data1': ambience_sentiment_score, 'data2': 0, 'maxValue': 150},\n",
        "        { 'subject': 'Experience', 'data1': experience_sentiment_score, 'data2': 0, 'maxValue': 150}\n",
        "])\n",
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[{\"subject\": \"Food\", \"data1\": 139, \"data2\": 0, \"maxValue\": 150}, {\"subject\": \"Service\", \"data1\": 125, \"data2\": 0, \"maxValue\": 150}, {\"subject\": \"Speed\", \"data1\": 75, \"data2\": 0, \"maxValue\": 150}, {\"subject\": \"Price\", \"data1\": 140, \"data2\": 0, \"maxValue\": 150}, {\"subject\": \"Ambience\", \"data1\": 140, \"data2\": 0, \"maxValue\": 150}, {\"subject\": \"Experience\", \"data1\": 143, \"data2\": 0, \"maxValue\": 150}]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E95ZxoLsPCTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')# region can be any choose one close to you below\n",
        "# # https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html\n",
        "                \n",
        "# text = l7\n",
        "# print(json.dumps(comprehend.batch_detect_sentiment(TextList=text, LanguageCode='en'), sort_keys=True, indent=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNW6Uz0hUcWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # tallylib/sentiment.py\n",
        "\n",
        "# import re\n",
        "# import nltk\n",
        "# import json\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from nltk.corpus import wordnet \n",
        "# from gensim.utils import simple_preprocess\n",
        "# from gensim.parsing.preprocessing import STOPWORDS\n",
        "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
        "\n",
        "# from tallylib.sql import getLatestReviews\n",
        "\n",
        "\n",
        "# def yelpReviewSentiment(business_id):\n",
        "# \tdata = getLatestReviews(business_id, limit=200)\n",
        "# \tif len(data)==0:\n",
        "# \t\treturn {}\n",
        "# \tdf = pd.DataFrame(data, columns=['date', 'text', 'stars'])\n",
        "# \tdel data\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/cafesFromDB.csv')\n",
        "#command ran in database\n",
        "# select * from tallyds.yelp_review where text like '%cafe%' order by business_id limit 500;\n",
        "\n",
        "df = df[df['business_id'] == '0d6kx6Jlocw77y1J9nbqMA']# just work with one popular cafe\n",
        "\n",
        "\n",
        "def tokenizer(doc):\n",
        "\treturn [token for token in simple_preprocess(doc) \n",
        "\t\t\tif token not in STOPWORDS]\n",
        "\n",
        "\n",
        "def related_to_food(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('food.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_service(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('service.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_speed(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('wait.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_price(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('price.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_ambience(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('ambience.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "\n",
        "def related_to_experience(doc):\n",
        "\tword_similarity_list = []\n",
        "\tfor review_word in doc:\n",
        "\t\tsyns = wordnet.synsets(review_word) \n",
        "\t\tif len(syns) > 0:\n",
        "\t\t\tw1 = wordnet.synset(syns[0].name()) # n here denotes the tag noun\n",
        "\t\t\tw2 = wordnet.synset('experience.n.01') \n",
        "\t\t\tword_similarity_score = w1.wup_similarity(w2)\n",
        "\t\t\tif word_similarity_score !=None and word_similarity_score > 0.5:\n",
        "\t\t\t\tword_similarity_list.append(review_word)\n",
        "\treturn word_similarity_list\n",
        "\n",
        "\n",
        "def extract_subject_related_words():\n",
        "\tdf['text'] = df['text'].apply(lambda x:\" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
        "\tdf['cleaned'] = df['text'].apply(tokenizer)\n",
        "\tdf['words_related_to_food'] = df['cleaned'].apply(related_to_food)\n",
        "\tdf['words_related_to_service'] = df['cleaned'].apply(related_to_service)\n",
        "\tdf['words_related_to_speed'] = df['cleaned'].apply(related_to_speed)\n",
        "\tdf['words_related_to_price'] = df['cleaned'].apply(related_to_price)\n",
        "\tdf['words_related_to_ambience'] = df['cleaned'].apply(related_to_ambience)\n",
        "\tdf['words_related_to_experience'] = df['cleaned'].apply(related_to_experience)\n",
        "\n",
        "\n",
        "def get_list_reviews_containing_subject():\n",
        "\tfood_review_list = df[df['words_related_to_food'].map(len) > 1]['text'].tolist()\n",
        "\tservice_review_list = df[df['words_related_to_service'].map(len) > 1]['text'].tolist()\n",
        "\tspeed_review_list = df[df['words_related_to_speed'].map(len) > 1]['text'].tolist()\n",
        "\tprice_review_list = df[df['words_related_to_price'].map(len) > 1]['text'].tolist()\n",
        "\tambience_review_list = df[df['words_related_to_ambience'].map(len) > 1]['text'].tolist()\n",
        "\texperience_review_list = df[df['words_related_to_experience'].map(len) > 1]['text'].tolist()\n",
        "\treturn food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list\n",
        "\n",
        "\n",
        "\n",
        "def sentiment_score(sentence):\n",
        "\t# Create a SentimentIntensityAnalyzer object. \n",
        "\tsid_obj = SentimentIntensityAnalyzer()\n",
        "\t# polarity_scores method of SentimentIntensityAnalyzer oject gives a sentiment dictionary. which contains pos, neg, neu, and compound scores. \n",
        "\tsentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "\n",
        "\treturn sentiment_dict\n",
        "\n",
        "\n",
        "def get_sentiment(review_list):\n",
        "\tall_sentiments = []\n",
        "\tcompounds = []\n",
        "\n",
        "\tif len(review_list) > 0:\n",
        "\t\tfor review in review_list:\n",
        "\t\t\tscore = sentiment_score(review)\n",
        "\t\t\tall_sentiments.append(score)\n",
        "\n",
        "\tif len(all_sentiments) > 0:\n",
        "\t\tfor sentiment_dict in all_sentiments:\n",
        "\t\t\tcompound = sentiment_dict['compound']\n",
        "\t\t\tcompounds.append(compound)\n",
        "\n",
        "\tif len(compounds) > 0:\n",
        "\t\tavg_sentiment = sum(compounds) / len(compounds)\n",
        "\t\n",
        "\telse:\n",
        "\t\tavg_sentiment = None\n",
        "\n",
        "\treturn avg_sentiment\n",
        "\n",
        "\n",
        "# def get_scores():\n",
        "# \tif len(food_review_list) > 0:\n",
        "# \t\tfood_sentiment_score = round((get_sentiment(food_review_list))*150)\n",
        "# \t\tif food_sentiment_score < 0:\n",
        "# \t\t\tfood_sentiment_score = 0\n",
        "# \telse: \n",
        "# \t\tfood_sentiment_score = 75\n",
        "# \tif len(service_review_list) > 0:\n",
        "# \t\tservice_sentiment_score = round((get_sentiment(service_review_list))*150)\n",
        "# \t\tif service_sentiment_score < 0:\n",
        "# \t\t\tservice_sentiment_score = 0\n",
        "# \telse: \n",
        "# \t\tservice_sentiment_score = 75\n",
        "# \tif len(speed_review_list) > 0:\n",
        "# \t\tspeed_sentiment_score = round((get_sentiment(speed_review_list))*150)\n",
        "# \t\tif speed_sentiment_score < 0:\n",
        "# \t\t\tspeed_sentiment_score = 0\n",
        "# \telse: \n",
        "# \t\tspeed_sentiment_score = 75\n",
        "# \tif len(price_review_list) > 0:\n",
        "# \t\tprice_sentiment_score = round((get_sentiment(price_review_list))*150)\n",
        "# \t\tif price_sentiment_score < 0:\n",
        "# \t\t\tprice_sentiment_score = 0\n",
        "# \telse: \n",
        "# \t\tprice_sentiment_score = 75\n",
        "# \tif len(ambience_review_list) > 0:\n",
        "# \t\tambience_sentiment_score = round((get_sentiment(ambience_review_list))*150)\n",
        "# \t\tif ambience_sentiment_score < 0:\n",
        "# \t\t\tambience_sentiment_score = 0\n",
        "# \telse: \n",
        "# \t\tambience_sentiment_score = 75\n",
        "# \tif len(experience_review_list) > 0:\n",
        "# \t\texperience_sentiment_score = round((get_sentiment(experience_review_list))*150)\n",
        "# \t\tif experience_sentiment_score < 0:\n",
        "# \t\t\texperience_sentiment_score = 0\n",
        "# \telse: \n",
        "# \t\texperience_sentiment_score = 75\n",
        "# \treturn food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score\n",
        "\n",
        "def get_scores():\n",
        "\tsubspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
        "\tscore_results = []\n",
        "\tfor subjectreviews in subspecreviews:\n",
        "\t\tif len(subjectreviews) > 0:\n",
        "\t\t\tsub_sentiment_score = round((get_sentiment(subjectreviews))*150)\n",
        "\t\t\tif sub_sentiment_score < 0:\n",
        "\t\t\t\tsub_sentiment_score = 0\n",
        "\t\telse: \n",
        "\t\t\tsub_sentiment_score = 75\n",
        "\t\t\tscore_results.append(sub_sentiment_score)\n",
        "\treturn score_results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "extract_subject_related_words()\n",
        "food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list = get_list_reviews_containing_subject()\n",
        "subspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
        "result = get_scores()\n",
        "\t\n",
        "\n",
        "# result = json.dumps([\n",
        "# \t\t\t{ 'subject': 'Food', 'data1': food_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "# \t\t\t{ 'subject': 'Service', 'data1': service_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "# \t\t\t{ 'subject': 'Speed', 'data1': speed_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "# \t\t\t{ 'subject': 'Price', 'data1': price_sentiment_score, 'data2': 0, 'maxValue': 150 },\n",
        "# \t\t\t{ 'subject': 'Ambience', 'data1': ambience_sentiment_score, 'data2': 0, 'maxValue': 150},\n",
        "# \t\t\t{ 'subject': 'Experience', 'data1': experience_sentiment_score, 'data2': 0, 'maxValue': 150}\n",
        "# ])\n",
        "\n",
        "# del [food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score]\n",
        "\n",
        "# \treturn result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vh-ACUesJxa",
        "colab_type": "code",
        "outputId": "773c7f8b-ab2b-4387-cfe2-8d260fa3107f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj0kAD5iaLw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score = get_scores()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwH4cD2EWRzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Thoughts on condensing function\n",
        "\n",
        "# scoreslist = [food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score]\n",
        "# for score in scoreslist:\n",
        "#   viztype4 = {\n",
        "#       'subject': 'Food', 'data1': scoreslist[0], 'data2': 0, 'maxValue': 150 },\n",
        "#       'subject': 'Service', 'data1': scoreslist[1], 'data2': 0, 'maxValue': 150 },\n",
        "#       'subject': 'Speed', 'data1': scoreslist[2], 'data2': 0, 'maxValue': 150 },\n",
        "#       'subject': 'Price', 'data1': scoreslist[3], 'data2': 0, 'maxValue': 150 },     \n",
        "#       'subject': 'Ambience', 'data1': scoreslist[4], 'data2': 0, 'maxValue': 150 },\n",
        "#       'subject': 'Experience', 'data1': scoreslist[5], 'data2': 0, 'maxValue': 150 },   \n",
        "#   }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jld8INQZSbC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Sample\n",
        "# [\n",
        "#         { subject: 'Subject 1', data1: 45, data2: 70, maxValue: 150 },\n",
        "#         { subject: 'Subject 2', data1: 75, data2: 95, maxValue: 150 },\n",
        "#         { subject: 'Subject 3', data1: 20, data2: 50, maxValue: 150 },\n",
        "#         { subject: 'Example Subject 4', data1: 65, data2: 85, maxValue: 150 },\n",
        "#         { subject: 'Food', data1: 35, data2: 45, maxValue: 150}\n",
        "# ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geiQaZPFeG44",
        "colab_type": "code",
        "outputId": "3231b2f9-b866-4443-f14e-32753bbf3bfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def get_scores():\n",
        "  subspecreviews = [food_review_list, service_review_list, speed_review_list, price_review_list, ambience_review_list, experience_review_list]\n",
        "  score_results = []\n",
        "  for subjectreviews in subspecreviews:\n",
        "    if len(subjectreviews) > 0:\n",
        "      sub_sentiment_score = round((get_sentiment(subjectreviews))*150)\n",
        "      if sub_sentiment_score < 0:\n",
        "        sub_sentiment_score = 0\n",
        "    else: \n",
        "      sub_sentiment_score = 75\n",
        "    score_results.append(sub_sentiment_score)\n",
        "  return score_results\n",
        "[food_sentiment_score, service_sentiment_score, speed_sentiment_score, price_sentiment_score, ambience_sentiment_score, experience_sentiment_score] = get_scores()\n",
        "food_sentiment_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOTtmlLJgAoR",
        "colab_type": "code",
        "outputId": "fa0047b2-25df-41da-ea89-5f6b735170f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "experience_sentiment_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sosz_EoqYui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
